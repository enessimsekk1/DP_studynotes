{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tOoyQ70H00_s"
   },
   "source": [
    "## Exercise 2\n",
    "In the course you learned how to do classificaiton using Fashion MNIST, a data set containing items of clothing. There's another, similar dataset called MNIST which has items of handwriting -- the digits 0 through 9.\n",
    "\n",
    "Write an MNIST classifier that trains to 99% accuracy or above, and does it without a fixed number of epochs -- i.e. you should stop training once you reach that level of accuracy.\n",
    "\n",
    "Some notes:\n",
    "1. It should succeed in less than 10 epochs, so it is okay to change epochs= to 10, but nothing larger\n",
    "2. When it reaches 99% or greater it should print out the string \"Reached 99% accuracy so cancelling training!\"\n",
    "3. If you add any additional variables, make sure you use the same names as the ones used in the class\n",
    "\n",
    "I've started the code for you below -- how would you finish it? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import path, getcwd, chdir\n",
    "\n",
    "# DO NOT CHANGE THE LINE BELOW. If you are developing in a local\n",
    "# environment, then grab mnist.npz from the Coursera Jupyter Notebook\n",
    "# and place it inside a local folder and edit the path to that location\n",
    "path = f\"{getcwd()}/../tmp2/mnist.npz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9rvXQGAA0ssC"
   },
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "    \n",
    "    class myCallback(tf.keras.callbacks.Callback):\n",
    "      def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('accuracy') is not None and logs.get('accuracy') > 0.99:\n",
    "          print(\"\\nReached 99% accuracy so cancelling training!\")\n",
    "          self.model.stop_training = True\n",
    "\n",
    "    mnist = tf.keras.datasets.mnist\n",
    "\n",
    "    (x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "    x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "    callbacks = myCallback()\n",
    "\n",
    "    model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "      tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # model fitting\n",
    "    history = model.fit(# YOUR CODE SHOULD START HERE\n",
    "        x_train, y_train, epochs = 9, callbacks = [callbacks]\n",
    "              # YOUR CODE SHOULD END HERE\n",
    "    )\n",
    "    # model fitting\n",
    "    return history.epoch, history.history['acc'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "1875/1875 [==============================] - 115s 61ms/step - loss: 0.2009 - accuracy: 0.9402\n",
      "Epoch 2/9\n",
      "1875/1875 [==============================] - 112s 60ms/step - loss: 0.0807 - accuracy: 0.9753\n",
      "Epoch 3/9\n",
      "1875/1875 [==============================] - 98s 53ms/step - loss: 0.0544 - accuracy: 0.9824\n",
      "Epoch 4/9\n",
      "1875/1875 [==============================] - 97s 52ms/step - loss: 0.0360 - accuracy: 0.9887\n",
      "Epoch 5/9\n",
      "1875/1875 [==============================] - 93s 50ms/step - loss: 0.0269 - accuracy: 0.9913\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d3617ae8770d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-28b3003e4f66>\u001b[0m in \u001b[0;36mtrain_mnist\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m# model fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    }
   ],
   "source": [
    "train_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "introduction-tensorflow",
   "graded_item_id": "d6dew",
   "launcher_item_id": "FExZ4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
